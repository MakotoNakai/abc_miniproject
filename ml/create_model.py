# -*- coding: utf-8 -*-
"""create_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NY755mw4D6WfkMo7C7xtwBNOxhRVx5ot
"""
# General libraries
from pandas.io.parsers import ParserError
import pandas as pd
import numpy as np
import zipfile
import glob

# Python libraries for machine learning
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from keras.models import Sequential
from keras.layers import Dense
import tensorflow as tf

with zipfile.ZipFile('/content/hw2_dataset.zip') as existing_zip:
    existing_zip.extractall()

data_sit_list = []
data_walk_list = []
data_steps_list = []

for dir in dirs:

    dir_sit = glob.glob(dir + '/*sit*')
    for sit_file in dir_sit:
        try:
            data_sit = pd.read_csv(sit_file)
            if list(data_sit.columns) == ['xmax', 'xmin', 'xave', 'xvar', 'ymax', 'ymin', 'yave', 'yvar', 'zmax', 'zmin', 'zave', 'zvar']:
                data_sit['label'] = 0
                data_sit_list.append(data_sit)
        except ParserError:
            pass
        except UnicodeDecodeError:
            print(sit_file)

    dir_walk = glob.glob(dir + '/*walk*')
    for walk_file in dir_walk:
        try:
            data_walk = pd.read_csv(walk_file)
            if list(data_walk.columns) == ['xmax', 'xmin', 'xave', 'xvar', 'ymax', 'ymin', 'yave', 'yvar', 'zmax', 'zmin', 'zave', 'zvar']:
                data_walk['label'] = 1
                data_walk_list.append(data_walk)
        except ParserError:
            pass

    dir_steps = glob.glob(dir + '/*steps*')
    for steps_file in dir_walk:
        try:
            data_steps = pd.read_csv(steps_file)
            if list(data_steps.columns) == ['xmax', 'xmin', 'xave', 'xvar', 'ymax', 'ymin', 'yave', 'yvar', 'zmax', 'zmin', 'zave', 'zvar']:
                data_steps['label'] = 2
                data_steps_list.append(data_steps)
        except ParserError:
            pass

df_sit = pd.concat(data_sit_list, axis=0, sort=True)
df_sit.to_csv("/content/sit.csv", index=False)

df_walk = pd.concat(data_walk_list, axis=0, sort=True)
df_walk.to_csv("/content/walk.csv", index=False)

df_steps = pd.concat(data_steps_list, axis=0, sort=True)
df_steps.to_csv("/content/steps.csv", index=False)

df_list = [df_sit, df_walk, df_steps]
df = pd.concat(df_list, axis=0, sort=True)
df.to_csv("/content/data.csv", index=False)

df = pd.read_csv("/content/data.csv")


features = df.iloc[:, 1:14].values
labels = df['label'].values
for i in range(features.shape[1]):
    features[:, i] = pd.to_numeric(features[:, i], errors='coerce')
features = np.nan_to_num(features)

x = features
y = np.ravel(labels)
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)

sc = StandardScaler()
sc.fit(x_train)
x_train_std = sc.transform(x_train)
x_test_std = sc.transform(x_test)

model = Sequential()
model.add(Dense(12, input_dim=12, activation='relu'))
model.add(Dense(8, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
# compile the keras model
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
# fit the keras model on the dataset
model.fit(x_train, y_train, epochs=150, batch_size=10)
# evaluate the keras model
_, accuracy = model.evaluate(x_test, y_test)
print('Accuracy: %.2f' % (accuracy*100))

model.save("/content/model.h5")

converter = tf.compat.v1.lite.TFLiteConverter.from_keras_model_file("/content/model.h5")
tflite_model = converter.convert()
open("/content/model.tflite", "wb").write(tflite_model)
